+++ 
title = 'Interactive Information Expansion'
date = 2025-06-17
+++ 

# Interactive Information Expansion
 
I've found that some the most useful writing on AI is that of the kind that goes "Here's how I use
AI/LLMs/ChatGPT as an X" where X is usually a programmer or a researcher of some kind. 
[Simon Willison](https://simonwillison.net/series/using-llms/), for example, has a series called [How I use LLMs and ChatGPT](https://simonwillison.net/series/using-llms/)
that gives you a decent picture of where AI is actually useful, instead of having to take someone's
word for it.)

One of the reasons why teaching -- and presenting information in general -- is hard is that you're
often presenting the information to different kinds of people with different backgrounds, different
amounts of context, and with varying levels of intelligence and comprehension. This is one of those
classic issues in teaching. You're often explaining at a pace that is too slow for some, and too
fast for others. At other times, you're presenting information that is too deep for those who only
want a shallow understanding of the topic, or too brief for those who want to know the details.

This issue of pace is certainly more common in lectures and video materials because textual forms
(i.e., textbooks, lecture notes, papers) allow the reader to consume the information at their own
pace. So, someone who has plenty of context regarding the material at hand might just skim through
the text. Whereas, someone who hasn't been familiarized with the terminology yet, or hasn't gone
through the necessary prerequisites to understand the material at hand, can read through the text
more slowly, possibly rereading multiple times.

The problem with traditional text formats with regards to the former case is that the learner still
has to spend energy and time skimming through the text -- even if very little to no information is
being retrieved. In the process, the learner could miss important information that they would have
wanted to pay attention to otherwise. Skimming could also make the reader feel disengaged or bored.

The problem with the latter case (i.e., slowing down the pace or rereading when something is too
challenging) is that it doesn't always work. The alternatives in this case often are: (1) reading
something that's adjacent to what we're trying to learn, (2) reading a textbook on the same topic
that's less technical or easier to approach for our current level of understanding, (3) working
through exercises, or (4) changing the learning medium (e.g., going from text to video). After going
through some of these options, one could go back to tackling the topic at hand more prepared than
before.

Now, I don't really know how college students are using AI right now, but LLMs offer something
that's pretty tangible when it comes to solving this issue of pace and verbosity in learning. The
ability to go through some text, find something you don't quite understand, and then have the LLM
explain that for you is not only useful in the sense that you get more information, but it also
means that you now have a knob which you can turn to control how much time and energy you want to
invest in one topic. You control the depth, verbosity, language, examples, and tone used to explain
a topic. 

You can decide if, instead of using fictional or over-simplified "textbook examples," you want to
read about actual real-world applications of the thing you're reading -- or you can do the opposite:
you may decide that you don't want to get bogged down into the implementation details of something
and ask for a simplified example, instead. 

You could perhaps use your current knowledge and prompt the LLM to find differences between the
information you currently have and the one you want to obtain. (This is why books like "Java for C++
programmers" exists, for example.) This makes it easier to form new connections, increasing the
likelihood that you remember the information at hand.

You can test your current understanding by posing a question which would showcase whether your
mental model is accurate or not. There's no societal pressure about being wrong. If your current
understanding is incorrect, you get to test it before you start building on top of a flawed mental
model.

You can go from not understanding a sentence to gathering information incrementally by alternating
between the levels of depth to adapt to the level of effort that you're willing to put in to
internalize that information. 

This sounds very similar to having a personal tutor. You get many of the
benefits of having a real tutor (see [Bloom's 2 sigma problem](https://en.wikipedia.org/wiki/Bloom's_2_sigma_problem)), 
but this one has more energy and patience and won't judge you like a normal tutor would.

Now for a cold shower, because LLMs are still far from being perfect. What I'm talking about here is
still normative: I would like for the depth/verbosity knobs to be reliable, but that's not always
the case. Some models are particularly verbose and instructing them otherwise sometimes result in
missing information, rather than conciseness. Another issue where these models fail sometimes is
when you want something very specific. Sometimes the amount of effort it takes to get that specific
thing often outweighs the amount of effort that you would have otherwise spent on just looking at a
more comprehensive source of information like a book or a paper.

LLMs do not replicate the captivating energy of a really good tutor, nor can they replicate a
personality that has a consistent philosophy with strong opinions on certain matters. They're often
very dull so they're probably better off being used as tools for enhancing learning rather than
replacing conventional methods.

Many of the benefits I mentioned here seem to suggest that we're getting closer to a form of
personalized learning by customizing the education experience to meet the goals and specifics of
the student. If you are interested to learn more about how we can use AI to improve education,
check out Andy Matuschak's [How might we learn?](https://andymatuschak.org/hmwl) presentation. 
He presents a demo which could give you a glimpse into what future education tools could look like.

